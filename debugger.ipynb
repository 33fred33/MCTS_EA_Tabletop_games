{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import os\n",
    "import statistics as st\n",
    "import plotly.graph_objects as go\n",
    "import random as rd\n",
    "import time\n",
    "import pandas as pd\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "import Utilities.experiment_utils as eu\n",
    "import unit_test as ut\n",
    "import Games.mnk as mnk\n",
    "import Games.Carcassonne.Carcassonne as carc\n",
    "#import Games.carcassonne_older as csn\n",
    "import Agents.random as arand\n",
    "import Agents.vanilla_mcts as mcts \n",
    "import Agents.siea_mcts as siea_mcts\n",
    "import Agents.mcts_rave as rave_mcts\n",
    "import Games.function_optimisation as fo\n",
    "import Utilities.logs_management as lm\n",
    "import Games.chess_64 as chess_64\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#cProfile.run(\"wins =  random_games(10000, base_gs)\")\n",
    "#ut.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"snow_queen\":{\"traits\":null,\"set\":\"The First Chapter\",\"lore-value\":1,\"color\":\"Amethyst\",\"strength\":2,\"artist\":\"Nicholas Kole\",\"willpower\":3,\"type\":\"character\",\"flavor_text\":\"Recreated by magical ink, Elsa found herself in an unfamiliar new world. Fortunately, ice works the same way everywhere.\",\"subtypes\":[\"Dreamborn\",\"Hero\",\"Queen\",\"Sorcerer\"],\"set-code\":\"TFC\",\"abilities\":[{\"FREEZE\":\"Excert chosen opposing character.\"}],\"inkable\":true,\"subtitle\":\"Snow Queen\",\"image-urls\":[{\"small\":\"https://lorcana-api.com/images/elsa/snow_queen/small.png\",\"no-art\":\"https://lorcana-api.com/images/elsa/snow_queen/no-art.png\",\"large\":\"https://lorcana-api.com/images/elsa/snow_queen/large.png\",\"art-crop\":\"https://lorcana-api.com/images/elsa/snow_queen/art-crop.png\",\"medium\":\"https://lorcana-api.com/images/elsa/snow_queen/medium.png\"}],\"name\":\"Elsa\",\"ink-cost\":3}}'\n",
      "b'[\\n    \"simba-protective_cub\",\\n    \"white_rabbits_pocket_watch\",\\n    \"lefou-instigator\",\\n    \"mickey_mouse-steamboat_pilot\",\\n    \"peter_pan-never_landing\",\\n    \"aladdin-prince_ali\",\\n    \"cinderella-gentle_and_kind\",\\n    \"frying_pan\",\\n    \"friends_on_the_other_side\",\\n    \"moana-chosen_by_the_ocean\",\\n    \"magic_golden_flower\",\\n    \"ariel-on_human_legs\",\\n    \"elsa-snow_queen\",\\n    \"stitch-new_dog\",\\n    \"cheshire_cat\",\\n    \"tinker_bell-most_helpful\",\\n    \"plasma_blaster\",\\n    \"tigger-wonderful_thing\",\\n    \"timon-grub_rustler\",\\n    \"hades-king_of_olympus\",\\n    \"cheshire_car-not_all_there\",\\n    \"cut_to_the_chase\",\\n    \"aladdin-cornered_swordsman\",\\n    \"beast\\'s_mirror\",\\n    \"scar-mastermind\",\\n    \"zeus-god_of_lightning\",\\n    \"magic_broom-bucket_brigade\",\\n    \"fishbone_quill\",\\n    \"stitch-carefree_surfer\",\\n    \"maleficent-uninvited\",\\n    \"gramma_tala-storyteller\",\\n    \"maui-hero_to_all\",\\n    \"magic_mirror\",\\n    \"merlin-self-appointed_mentor\",\\n    \"work_together\",\\n    \"maximus\",\\n    \"part_of_your_world\",\\n    \"kristoff-offical_ice_master\",\\n    \"rapunzel-letting_down_her_hair\",\\n    \"cruella_de_vil-miserable_as_usual\",\\n    \"gaston-arrogant_hunter\",\\n    \"develop_your_brain\",\\n    \"sven-offical_ice_deliverer\",\\n    \"beast-wolfsbane\",\\n    \"aladdin-heroic_outlaw\",\\n    \"one_jump_ahead\",\\n    \"lady_tremaine\",\\n    \"mad_hatter-gracious_host\",\\n    \"donald_duck-boisterous_fowl\",\\n    \"smash\",\\n    \"lilo-galactic_hero\",\\n    \"dragon_fire\",\\n    \"dr._facilier-agent_provocateur\",\\n    \"scar-fiery_usurper\",\\n    \"maleficent_2\",\\n    \"donald_duck-musketeer\",\\n    \"jasmine-queen_of_agrabah\",\\n    \"prince_eric-dashing_and_brave\",\\n    \"stitch-rock_star\",\\n    \"lantern\",\\n    \"anna-heir_to_arendelle\",\\n    \"mr._smee-loyal_first_mate\",\\n    \"white_rabbit\\'s_pocket_watch\",\\n    \"heihei-boat_snack\",\\n    \"kronk-right-handed_man\",\\n    \"jetsam-ursula\\'s_spy\",\\n    \"hercules-true_hero\",\\n    \"stitch-abomination\",\\n    \"robin_hood-unrivaled_archer\",\\n    \"healing_glow\",\\n    \"iago-loud-mouthed_parrot\",\\n    \"mickey_mouse-wayward_sorcerer\",\\n    \"prince_phillip-dragonslayer\",\\n    \"simba-returned_king\",\\n    \"let_it_go\",\\n    \"pongo-ol\\'_rascal\",\\n    \"cerebus-three-headed_dog\",\\n    \"mickey_mouse-detective\",\\n    \"sergeant_tibbs-courageous_cat\",\\n    \"rafiki-mysterious_sage\",\\n    \"starkey-hook\\'s_henchman\",\\n    \"genie-on_the_job\",\\n    \"goofy-daredevil\",\\n    \"ursula-power_hungry\",\\n    \"dr._facilier\\'s_cards\",\\n    \"dr._facilier-remarkable_genteman\",\\n    \"steal_from_the_rich\",\\n    \"he\\'s_got_a_sword!\",\\n    \"te_ka-heartless\",\\n    \"jafar-wicked_sorcerer\",\\n    \"ransack\",\\n    \"maurice-world-famour_inventor\",\\n    \"philoctetes-trainer_of_heroes\",\\n    \"hades-infernal_schemer\",\\n    \"tangle\",\\n    \"the_wardrobe-belle\\'s_confident\",\\n    \"lilo-making_a_wish\",\\n    \"flounder-voice_of_reason\",\\n    \"dinglehopper\",\\n    \"captain_hook-captain_of_the_jolly_roger\",\\n    \"coconut_basket\",\\n    \"jasmine-disguised\",\\n    \"mufasa-king_of_the_pride_lands\",\\n    \"mulan-imperial_soilder\",\\n    \"the_queen-wicked_and_vain\",\\n    \"tinker_bell-giant_fairy\",\\n    \"goons-maleficent\\'s_underlings\",\\n    \"flotsam-ursula\\'s_spy\",\\n    \"mickey_mouse-brave_little_tailor\",\\n    \"minnie_mouse-beloved_princess\",\\n    \"olaf-friendly_snowman\",\\n    \"archimedes-highly_educated_owl\",\\n    \"beast-hardheaded\",\\n    \"peter_pan-fearless_fighter\",\\n    \"belle-strange_but_special\",\\n    \"mickey_mouse-true_friend\",\\n    \"te_ka-the_burning_one\",\\n    \"pascal-rapunzel\\'s_companion\",\\n    \"aurora-regal_princess\",\\n    \"sebastion-court_composer\",\\n    \"mother_gothel-selfish_manipulator\",\\n    \"sword_of_truth\",\\n    \"maleficent-sinister_visitor\",\\n    \"genie-powers_unleashed\",\\n    \"control_your_temper!\",\\n    \"yzma-alchemist\",\\n    \"shield_of_virtue\",\\n    \"eye_of_the_fates\",\\n    \"captain-colonel\\'s_lieutenant\",\\n    \"goofy-musketeer\",\\n    \"mickey_mouse-musketeer\",\\n    \"helllotest-jimmy-the-finger\",\\n    \"be_our_guest\",\\n    \"jumba_jookiba-renegade_scientist\",\\n    \"alladdin-street_rat\",\\n    \"maleficent-biding_her_time\",\\n    \"triton-the_sea_king\",\\n    \"belle-inventive_engineer\",\\n    \"chief_tui-respected_leader\",\\n    \"donald_duck-strutting_his_stuff\",\\n    \"duke_of_weselton-opportunistic_official\",\\n    \"tamatoa-so_shiny!\",\\n    \"pumbaa-friendly_warthog\",\\n    \"maui-demigod\",\\n    \"tamatoa-drab_little_crab\",\\n    \"lefou-bumbler\",\\n    \"captain_hook-forceful_duelist\",\\n    \"maleficent-sorceress\",\\n    \"captain_hook-ruthless_pirate\",\\n    \"simba-rightful_heir\",\\n    \"dr._facilier-charlatan\",\\n    \"simba-future_king\",\\n    \"fire_the_cannons!\",\\n    \"gantu-galactic_federation_captain\",\\n    \"the_beast_is_mine!\",\\n    \"hades-lord_of_the_underworld\",\\n    \"just_in_time\"\\n]'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "response = requests.get('https://api.lorcana-api.com/strict/elsa')\n",
    "if response.status_code == 200:\n",
    "    print(response.content)\n",
    "else:\n",
    "    print('Request failed with status code:', response.status_code)\n",
    "response = requests.get('https://api.lorcana-api.com/lists/names')\n",
    "if response.status_code == 200:\n",
    "    print(response.content)\n",
    "else:\n",
    "    print('Request failed with status code:', response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get('https://api.lorcana-api.com/lists/names')\n",
    "if response.status_code == 200:\n",
    "    print(response.content)\n",
    "else:\n",
    "    response_string = str(response.content).split(\"\\\\n\")\n",
    "    names = []\n",
    "    for raw_name in response_string:\n",
    "        if \",\" in raw_name:\n",
    "            #print(raw_name)\n",
    "            name = raw_name.replace(\"\\\"\", \"\")\n",
    "            # replace \\ with nothing\n",
    "            name = name.replace(\"\\\\\", \"\")\n",
    "            name = name.replace(\" \", \"\")\n",
    "            name = name.replace(\",\", \"\")\n",
    "            if name == \"mr\": name = \"mr_smee\"\n",
    "            if name == \"dr\": name = \"dr_facilier\"\n",
    "            print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x144 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color_palette = ['#8cae8b', '#667295', '#8d450d']\n"
     ]
    }
   ],
   "source": [
    "color_palette = [ \"#B10909\" #red\n",
    "                ,  \"#5B8C5A\"#green\n",
    "                ,\"#56638A\" #blue-purple\n",
    "                , \"#EC7316\" #orange\n",
    "                ,  \"#FC738C\" ] #pink\n",
    "color_palette = [\"#5B8C5A\"\n",
    "                ,\"#56638A\"\n",
    "                , \"#EC7316\"]\n",
    "color_palette[2] = eu.color_rgb_to_hex(eu.darken_color(eu.color_hex_to_rgb(color_palette[2]), 0.4))\n",
    "color_palette[0] = eu.color_rgb_to_hex(eu.brighten_color(eu.color_hex_to_rgb(color_palette[0]), 0.3))\n",
    "color_palette[1] = eu.color_rgb_to_hex(eu.brighten_color(eu.color_hex_to_rgb(color_palette[1]), 0.1))\n",
    "\n",
    "eu.view_color_palette(color_palette)\n",
    "\n",
    "print(\"color_palette = {}\".format(color_palette))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing game 0 of 2, agents: ['Vanilla_MCTS', 'SIEA_MCTS']\n",
      "Playing game 1 of 2, agents: ['Vanilla_MCTS', 'SIEA_MCTS']\n",
      "Playing game 0 of 2, agents: ['SIEA_MCTS', 'Vanilla_MCTS']\n",
      "Playing game 1 of 2, agents: ['SIEA_MCTS', 'Vanilla_MCTS']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Utilities.experiment_utils.GamePlayer at 0x2876c7e0e80>,\n",
       " <Utilities.experiment_utils.GamePlayer at 0x28714d7e920>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcts_agent = mcts.MCTS_Player(max_iterations = 100)\n",
    "siea_mcts_agent = siea_mcts.SIEA_MCTS_Player(max_iterations = 100)\n",
    "#game_state = carc.CarcassonneState(initial_tile_quantities=[1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0])\n",
    "#game_state = carc.CarcassonneState(initial_tile_quantities=[1 for _ in range(24)])\n",
    "game_state = carc.CarcassonneState()\n",
    "#game_state = mnk.GameState(3,3,3)\n",
    "game_state.set_initial_state()\n",
    "#random_action = mcts_agent.choose_action(game_state)\n",
    "#random_action = mcts_agent.choose_action(game_state)\n",
    "#print(\"Max score\", game_state.max_possible_score)\n",
    "#print(random_action)\n",
    "#print(len(game_state.available_actions))\n",
    "#print(mcts_agent.view_mcts_tree())\n",
    "gp1, gp2 = eu.play_match([mcts_agent, siea_mcts_agent], game_state, 2, os.path.join(\"Outputs\", \"test_match_carc2\"), random_seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCTS_RAVE : Random move returned\n",
      "9\n",
      "\n",
      "0:Decision_node, edge:None, visits:0, avg_reward:nan, children:0, ret:, tree_policy_formula:None\n"
     ]
    }
   ],
   "source": [
    "#View tree on each iteration - STEP 1\n",
    "\n",
    "mcts_agent = rave_mcts.MCTS_RAVE(max_iterations = 0, rollouts=10)\n",
    "#mcts_agent = mcts.MCTS_Player(max_iterations = 0, rollouts=100)\n",
    "#mcts_agent = siea_mcts.SIEA_MCTS_Player(max_iterations = 0)\n",
    "#game_state = carc.CarcassonneState(initial_tile_quantities=[1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0])\n",
    "#game_state = carc.CarcassonneState(initial_tile_quantities=[1 for _ in range(24)])\n",
    "#game_state = carc.CarcassonneState()\n",
    "game_state = mnk.GameState(3,3,3)\n",
    "game_state.set_initial_state()\n",
    "random_action = mcts_agent.choose_action(game_state)\n",
    "#random_action = mcts_agent.choose_action(game_state)\n",
    "#print(\"Max score\", game_state.max_possible_score)\n",
    "#print(random_action)\n",
    "print(len(game_state.available_actions))\n",
    "print(mcts_agent.view_mcts_tree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0:Decision_node, edge:None, visits:56, avg_reward:0.286, children:9, ret:, tree_policy_formula:None\n",
      "--1:Decision_node, edge:(x2,y1,t0), visits:6, avg_reward:0.283, children:5, ret:,amaf_v191,amaf_avg_r:0.236, tree_policy_formula:1.43\n",
      "----14:Decision_node, edge:(x1,y2,t1), visits:1, avg_reward:0.4, children:0, ret:,amaf_v12,amaf_avg_r:0, tree_policy_formula:1.69\n",
      "----24:Decision_node, edge:(x1,y0,t1), visits:1, avg_reward:0.4, children:0, ret:,amaf_v14,amaf_avg_r:0.143, tree_policy_formula:1.62\n",
      "----32:Decision_node, edge:(x0,y1,t1), visits:1, avg_reward:0.4, children:0, ret:,amaf_v2,amaf_avg_r:0, tree_policy_formula:1.65\n",
      "----38:Decision_node, edge:(x0,y2,t1), visits:1, avg_reward:0.4, children:0, ret:,amaf_v2,amaf_avg_r:0, tree_policy_formula:1.65\n",
      "----45:Decision_node, edge:(x1,y1,t1), visits:1, avg_reward:-0.2, children:0, ret:, tree_policy_formula:nan\n",
      "--2:Decision_node, edge:(x1,y1,t0), visits:10, avg_reward:0.55, children:8, ret:,amaf_v171,amaf_avg_r:0.591, tree_policy_formula:1.45\n",
      "----10:Decision_node, edge:(x0,y0,t1), visits:1, avg_reward:0.7, children:0, ret:,amaf_v19,amaf_avg_r:0.211, tree_policy_formula:1.68\n",
      "----18:Decision_node, edge:(x1,y2,t1), visits:1, avg_reward:0.6, children:0, ret:,amaf_v19,amaf_avg_r:0.474, tree_policy_formula:1.61\n",
      "----22:Decision_node, edge:(x0,y2,t1), visits:1, avg_reward:0.6, children:0, ret:,amaf_v23,amaf_avg_r:0.174, tree_policy_formula:1.75\n",
      "----25:Decision_node, edge:(x2,y1,t1), visits:1, avg_reward:0.8, children:0, ret:,amaf_v22,amaf_avg_r:0.5, tree_policy_formula:1.49\n",
      "----31:Decision_node, edge:(x1,y0,t1), visits:2, avg_reward:0.45, children:1, ret:,amaf_v6,amaf_avg_r:0.333, tree_policy_formula:1.1\n",
      "------55:Decision_node, edge:(x0,y2,t0), visits:1, avg_reward:0.8, children:0, ret:, tree_policy_formula:nan\n",
      "----39:Decision_node, edge:(x2,y2,t1), visits:1, avg_reward:0.1, children:0, ret:,amaf_v10,amaf_avg_r:0.7, tree_policy_formula:1.76\n",
      "----47:Decision_node, edge:(x0,y1,t1), visits:1, avg_reward:0.2, children:0, ret:,amaf_v7,amaf_avg_r:1, tree_policy_formula:1.57\n",
      "----54:Decision_node, edge:(x2,y0,t1), visits:1, avg_reward:0.9, children:0, ret:,amaf_v3,amaf_avg_r:0.333, tree_policy_formula:1.49\n",
      "--3:Decision_node, edge:(x1,y0,t0), visits:5, avg_reward:0.14, children:4, ret:,amaf_v163,amaf_avg_r:0.27, tree_policy_formula:1.43\n",
      "----16:Decision_node, edge:(x1,y1,t1), visits:1, avg_reward:-0.3, children:0, ret:,amaf_v8,amaf_avg_r:0.25, tree_policy_formula:1.84\n",
      "----33:Decision_node, edge:(x2,y0,t1), visits:1, avg_reward:0.7, children:0, ret:,amaf_v5,amaf_avg_r:0.2, tree_policy_formula:1.32\n",
      "----40:Decision_node, edge:(x0,y2,t1), visits:1, avg_reward:0.3, children:0, ret:,amaf_v4,amaf_avg_r:1, tree_policy_formula:1.18\n",
      "----50:Decision_node, edge:(x2,y1,t1), visits:1, avg_reward:0.2, children:0, ret:, tree_policy_formula:nan\n",
      "--4:Decision_node, edge:(x0,y0,t0), visits:6, avg_reward:0.267, children:5, ret:,amaf_v204,amaf_avg_r:0.382, tree_policy_formula:1.44\n",
      "----15:Decision_node, edge:(x2,y2,t1), visits:1, avg_reward:0.5, children:0, ret:,amaf_v18,amaf_avg_r:-0.222, tree_policy_formula:1.74\n",
      "----23:Decision_node, edge:(x1,y0,t1), visits:1, avg_reward:0.6, children:0, ret:,amaf_v11,amaf_avg_r:0.545, tree_policy_formula:1.32\n",
      "----29:Decision_node, edge:(x0,y2,t1), visits:1, avg_reward:-0.5, children:0, ret:,amaf_v8,amaf_avg_r:0.5, tree_policy_formula:1.92\n",
      "----43:Decision_node, edge:(x2,y1,t1), visits:1, avg_reward:0.4, children:0, ret:,amaf_v1,amaf_avg_r:-1, tree_policy_formula:1.96\n",
      "----53:Decision_node, edge:(x0,y1,t1), visits:1, avg_reward:0.5, children:0, ret:, tree_policy_formula:nan\n",
      "--5:Decision_node, edge:(x2,y2,t0), visits:7, avg_reward:0.343, children:6, ret:,amaf_v184,amaf_avg_r:0.451, tree_policy_formula:1.43\n",
      "----12:Decision_node, edge:(x1,y1,t1), visits:1, avg_reward:0.2, children:0, ret:,amaf_v23,amaf_avg_r:0.0435, tree_policy_formula:1.85\n",
      "----21:Decision_node, edge:(x2,y0,t1), visits:1, avg_reward:0.5, children:0, ret:,amaf_v19,amaf_avg_r:-0.0526, tree_policy_formula:1.74\n",
      "----30:Decision_node, edge:(x0,y2,t1), visits:1, avg_reward:0.7, children:0, ret:,amaf_v11,amaf_avg_r:0.273, tree_policy_formula:1.48\n",
      "----34:Decision_node, edge:(x0,y1,t1), visits:1, avg_reward:0.6, children:0, ret:,amaf_v6,amaf_avg_r:0.667, tree_policy_formula:1.34\n",
      "----41:Decision_node, edge:(x0,y0,t1), visits:1, avg_reward:0, children:0, ret:,amaf_v5,amaf_avg_r:-0.2, tree_policy_formula:2.06\n",
      "----51:Decision_node, edge:(x1,y0,t1), visits:1, avg_reward:0, children:0, ret:, tree_policy_formula:nan\n",
      "--6:Decision_node, edge:(x0,y1,t0), visits:5, avg_reward:0.2, children:4, ret:,amaf_v174,amaf_avg_r:0.172, tree_policy_formula:1.46\n",
      "----17:Decision_node, edge:(x1,y1,t1), visits:1, avg_reward:0.1, children:0, ret:,amaf_v16,amaf_avg_r:-0.0625, tree_policy_formula:1.77\n",
      "----27:Decision_node, edge:(x0,y0,t1), visits:1, avg_reward:0.6, children:0, ret:,amaf_v5,amaf_avg_r:0.6, tree_policy_formula:1.19\n",
      "----36:Decision_node, edge:(x2,y1,t1), visits:1, avg_reward:0.2, children:0, ret:,amaf_v3,amaf_avg_r:0.333, tree_policy_formula:1.54\n",
      "----46:Decision_node, edge:(x0,y2,t1), visits:1, avg_reward:0.2, children:0, ret:, tree_policy_formula:nan\n",
      "--7:Decision_node, edge:(x0,y2,t0), visits:5, avg_reward:0.16, children:4, ret:,amaf_v158,amaf_avg_r:0.411, tree_policy_formula:1.47\n",
      "----13:Decision_node, edge:(x1,y1,t1), visits:1, avg_reward:-0.5, children:0, ret:,amaf_v14,amaf_avg_r:0.286, tree_policy_formula:1.91\n",
      "----28:Decision_node, edge:(x0,y1,t1), visits:1, avg_reward:0.7, children:0, ret:,amaf_v5,amaf_avg_r:0.2, tree_policy_formula:1.32\n",
      "----37:Decision_node, edge:(x0,y0,t1), visits:1, avg_reward:0.1, children:0, ret:,amaf_v1,amaf_avg_r:1, tree_policy_formula:1.39\n",
      "----49:Decision_node, edge:(x2,y1,t1), visits:1, avg_reward:0.4, children:0, ret:, tree_policy_formula:nan\n",
      "--8:Decision_node, edge:(x1,y2,t0), visits:5, avg_reward:0.06, children:4, ret:,amaf_v183,amaf_avg_r:0.29, tree_policy_formula:1.37\n",
      "----19:Decision_node, edge:(x0,y0,t1), visits:1, avg_reward:0.5, children:0, ret:,amaf_v13,amaf_avg_r:0.0769, tree_policy_formula:1.5\n",
      "----26:Decision_node, edge:(x0,y2,t1), visits:1, avg_reward:-0.3, children:0, ret:,amaf_v8,amaf_avg_r:0.25, tree_policy_formula:1.84\n",
      "----44:Decision_node, edge:(x2,y2,t1), visits:1, avg_reward:0.3, children:0, ret:,amaf_v2,amaf_avg_r:0, tree_policy_formula:1.61\n",
      "----56:Decision_node, edge:(x2,y1,t1), visits:1, avg_reward:0.3, children:0, ret:, tree_policy_formula:nan\n",
      "--9:Decision_node, edge:(x2,y0,t0), visits:7, avg_reward:0.286, children:6, ret:,amaf_v178,amaf_avg_r:0.404, tree_policy_formula:1.37\n",
      "----11:Decision_node, edge:(x1,y2,t1), visits:1, avg_reward:0.3, children:0, ret:,amaf_v11,amaf_avg_r:0.273, tree_policy_formula:1.69\n",
      "----20:Decision_node, edge:(x0,y0,t1), visits:1, avg_reward:-0.2, children:0, ret:,amaf_v15,amaf_avg_r:0, tree_policy_formula:2.08\n",
      "----35:Decision_node, edge:(x0,y1,t1), visits:1, avg_reward:0.4, children:0, ret:,amaf_v9,amaf_avg_r:0.333, tree_policy_formula:1.6\n",
      "----42:Decision_node, edge:(x1,y1,t1), visits:1, avg_reward:0.6, children:0, ret:,amaf_v8,amaf_avg_r:0.125, tree_policy_formula:1.6\n",
      "----48:Decision_node, edge:(x2,y1,t1), visits:1, avg_reward:0.6, children:0, ret:,amaf_v4,amaf_avg_r:0.25, tree_policy_formula:1.53\n",
      "----52:Decision_node, edge:(x0,y2,t1), visits:1, avg_reward:-0.1, children:0, ret:, tree_policy_formula:nan\n"
     ]
    }
   ],
   "source": [
    "#View tree on each iteration - STEP 2 - Iterate\n",
    "\n",
    "#mcts iteration\n",
    "node = mcts_agent.root_node\n",
    "\n",
    "#Selection\n",
    "node = mcts_agent.selection(node)\n",
    "\n",
    "#Expansion\n",
    "if node.can_be_expanded():\n",
    "    node = mcts_agent.expansion(node)\n",
    "\n",
    "#Simulation\n",
    "reward = mcts_agent.simulation(node, mcts_agent.rollouts, mcts_agent.default_policy) \n",
    "\n",
    "#Backpropagation\n",
    "mcts_agent.backpropagation(node, reward)\n",
    "\n",
    "print(mcts_agent.view_mcts_tree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalGames = 10\n",
    "logs = True\n",
    "random_seed = 1\n",
    "if random_seed is not None: \n",
    "    rd.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "else: \n",
    "    random_seed = rd.randint(0, 2**32)\n",
    "    print(\"meh\")\n",
    "    rd.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "game_state = carc.CarcassonneState(initial_tile_quantities=[1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,2,1,0,0,0,0,0,0,0])\n",
    "#game_state = carc.CarcassonneState(initial_tile_quantities=[1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0])\n",
    "#game_state = mnk.GameState(m=3,n=3,k=3)\n",
    "game_state.set_initial_state()\n",
    "agent3 = arand.RandomPlayer()\n",
    "agent2 = mcts.MCTS_Player(max_iterations=100)\n",
    "players = [agent2, agent3]\n",
    "games_count = 0\n",
    "WinnerCount = {0:0, 1:0, \"Draw\":0}\n",
    "\n",
    "all_action_logs = pd.DataFrame()\n",
    "all_game_logs = pd.DataFrame()\n",
    "\n",
    "ST = time.time()\n",
    "\n",
    "for game in range(TotalGames):\n",
    "    #gs = game_state.duplicate()\n",
    "    gs = game_state.duplicate()\n",
    "\n",
    "    #Set logs\n",
    "    action_logs = pd.DataFrame()\n",
    "    game_logs = pd.DataFrame()\n",
    "    if logs:\n",
    "        for p in players:\n",
    "            p.logs = True\n",
    "\n",
    "    #Play game\n",
    "    safe_count = 0\n",
    "    while not gs.is_terminal:\n",
    "        start_time = time.time()\n",
    "        action = players[gs.player_turn].choose_action(gs)\n",
    "        #action = rd.choice(gs.available_actions)\n",
    "        selection_time = time.time() - start_time\n",
    "\n",
    "        #Update logs\n",
    "        if logs:\n",
    "            action_log = players[gs.player_turn].choose_action_logs #Assumes this log is single row\n",
    "            action_log[\"game_index\"] = games_count\n",
    "            action_log[\"selection_time\"] = selection_time\n",
    "            action_log[\"returned_action\"] = str(action)\n",
    "            action_log[\"pg_player\"] = str(players[gs.player_turn])\n",
    "            action_logs = pd.concat([action_logs, action_log], ignore_index=True)\n",
    "            game_logs = pd.concat([game_logs, gs.logs_data()], ignore_index=True)\n",
    "\n",
    "        #safety check      \n",
    "        safe_count += 1\n",
    "        if safe_count > 1000: \n",
    "            print(\"Safe count exceeded\")\n",
    "            print(gs.logs_data())\n",
    "            print(\"Last action:\" + str(action))\n",
    "            break\n",
    "        assert safe_count < 1000, \"Safe count exceeded\"\n",
    "\n",
    "        #Make action\n",
    "        gs.make_action(action)\n",
    "\n",
    "    if logs:\n",
    "        #Final logs by action\n",
    "        final_logs_by_action = pd.concat([action_logs, game_logs], axis=1)\n",
    "\n",
    "\n",
    "        #Final logs by game\n",
    "        final_logs_by_game_dict = {}\n",
    "        for i, player in enumerate(players):\n",
    "            final_logs_by_game_dict[\"Player_\" + str(i)] = str(player)\n",
    "        final_logs_by_game_dict[\"game_random_seed\"] = random_seed\n",
    "        final_logs_by_game_dict[\"game_index\"] = games_count\n",
    "        final_logs_by_game = pd.DataFrame(final_logs_by_game_dict, index=[0])\n",
    "        final_logs_by_game = pd.concat([final_logs_by_game, gs.logs_data()], axis=1)\n",
    "            \n",
    "    games_count += 1\n",
    "    if gs.winner is None:\n",
    "        WinnerCount[\"Draw\"] += 1\n",
    "    else: WinnerCount[gs.winner] += 1\n",
    "    print(\"Game\", games_count, \"ended, winner:\", gs.winner, \"scores:\", gs.Scores)\n",
    "\n",
    "    all_action_logs = pd.concat([all_action_logs, final_logs_by_action], ignore_index=True)\n",
    "    all_game_logs = pd.concat([all_game_logs, final_logs_by_game], ignore_index=True)\n",
    "\n",
    "ET = time.time()\n",
    "\n",
    "all_action_logs.to_csv(os.path.join(\"Outputs\",\"test_carc\",\"by_action.csv\"))\n",
    "all_game_logs.to_csv(os.path.join(\"Outputs\",\"test_carc\",\"by_game.csv\"))\n",
    "print(\"Games ended, time:\", str(ET - ST))\n",
    "print(\"WinnerCount\",WinnerCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evolved formulas analysis, now in experiment\n",
    "logs_path = os.path.join(\"Outputs\",\"FO_single_decision_new\")\n",
    "data = pd.read_csv(os.path.join(logs_path, \"logs_by_run.csv\"))\n",
    "evolved_formula_data = pd.DataFrame()\n",
    "for agent in data[\"Player\"].unique():\n",
    "    if \"EA\" in agent:\n",
    "        for f_index in data[\"Function_index\"].unique():\n",
    "            tdata = data[(data[\"Player\"]==agent) & (data[\"Function_index\"]==f_index)]\n",
    "            fa_data = eu.evolved_formula_analysis(tdata)\n",
    "            fa_data[\"Player\"] = [agent]\n",
    "            fa_data[\"Function_index\"] = [f_index]\n",
    "            evolved_formula_data = pd.concat([evolved_formula_data, fa_data])\n",
    "evolved_formula_data.to_csv(os.path.join(logs_path, \"evolved_formula_analysis.csv\"), mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe_state = game_state.duplicate()\n",
    "dupe_state.make_action(rd.choice(dupe_state.available_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in [\"evolution_logs.csv\"]:\n",
    "    experiment_path = os.path.join(\"Outputs\",\"FO_single_decision_new2\")\n",
    "    file_path_list = lm.find_log_files(file_name, experiment_path)\n",
    "    lm.combine_logs(experiment_path, file_name, file_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot histograms\n",
    "\n",
    "n_bins = 2**7\n",
    "experiment_path = os.path.join(\"Outputs\",\"FO_single_decision_new2\")\n",
    "file_path_list = lm.find_log_files(\"tree_data.csv\", experiment_path)\n",
    "print([\"\\n\" + f for f in file_path_list])\n",
    "for function_index in range(5):\n",
    "  data_list = []\n",
    "  subplot_titles = []\n",
    "  file_paths = []\n",
    "\n",
    "  #Add ea vanilla\n",
    "  paths_to_remove = []\n",
    "  for file_path in [f for f in file_path_list if \"Function_\" + str(function_index) in f]:\n",
    "      agent_name = file_path.split(os.sep)[-2]\n",
    "      if \"_c\" in agent_name:\n",
    "        data_list.append(pd.read_csv(file_path)) #mod to get interesting runs\n",
    "        if \"1_4142\" in agent_name:\n",
    "           agent_name= agent_name.replace(\"1_4142\", \"\\u221A\\u03052\\u0305\")\n",
    "        if \"0_5\" in agent_name:\n",
    "           agent_name= agent_name.replace(\"0_5\", \"0.5\")\n",
    "        agent_name = agent_name.replace(\"MCTS_\", \"MCTS \")\n",
    "        agent_name = agent_name.replace(\" c\", \" c = \")\n",
    "        subplot_titles += [agent_name]\n",
    "        file_paths += [file_path]\n",
    "        paths_to_remove += [file_path]\n",
    "  for path in paths_to_remove:\n",
    "    file_path_list.remove(path)\n",
    "\n",
    "  paths_to_remove = []\n",
    "  for file_path in [f for f in file_path_list if \"Function_\" + str(function_index) in f]:\n",
    "    agent_name = file_path.split(os.sep)[-2]\n",
    "    if \"EA_\" in agent_name and not \"SIEA_\" in agent_name:\n",
    "      data_list.append(pd.read_csv(file_path))\n",
    "      agent_name= agent_name.replace(\"_its\", \" \")\n",
    "      agent_name += \" iterations\"\n",
    "      subplot_titles += [agent_name]\n",
    "      file_paths += [file_path]\n",
    "  for path in paths_to_remove:\n",
    "    file_path_list.remove(path)\n",
    "\n",
    "  for file_path in [f for f in file_path_list if \"Function_\" + str(function_index) in f]:\n",
    "    agent_name = file_path.split(os.sep)[-2]\n",
    "    if \"SIEA_\" in agent_name:\n",
    "      data_list.append(pd.read_csv(file_path))  #mod to get interesting runs\n",
    "      agent_name= agent_name.replace(\"_its\", \" \")\n",
    "      agent_name += \" iterations\"\n",
    "      subplot_titles += [agent_name]\n",
    "      file_paths += [file_path]\n",
    "    \n",
    "  if subplot_titles != [] and data_list != []:\n",
    "    fop = fo.GameState(function_index=function_index)\n",
    "\n",
    "    #print(len(data_list))\n",
    "    \"\"\" #mod to get interesting runs\n",
    "    interesting_runs = [0,10,16,36,41,45,72,73,97]\n",
    "    interesting_data = []\n",
    "    interesting_titles = [\"Tunnel\",\"Even\",\"Random\", \"Exploratory\", \"Opposite\", \"Emergent 1\", \"Emergent 2\", \"Emergent 3\", \"UCB1 c=0.25\"]\n",
    "    interesting_titles = [\"Behaviour type \" + str(i) for i in range(len(interesting_runs))]\n",
    "    for j in range(10):\n",
    "      new_data_list = []\n",
    "      subplot_titles = []\n",
    "      dat = data_list[1]\n",
    "      for i in range(j*10,(j+1)*10):\n",
    "        tdat = dat.loc[dat[\"run\"] == i]\n",
    "        new_data_list = new_data_list + [tdat]\n",
    "        if i==40:\n",
    "          my_dat = tdat\n",
    "        if i in interesting_runs:\n",
    "          interesting_data += [tdat]\n",
    "        subplot_titles += [\"Run \" + str(i)]\n",
    "      subdata_list = new_data_list\n",
    "    \"\"\"\n",
    "\n",
    "    plot = eu.fo_tree_histogram_average(data_list,  #mod to get interesting runs\n",
    "                        fop.function, \n",
    "                        \"F\"+str(function_index+1) , #mod to get interesting runs\n",
    "                        divisions = 3,\n",
    "                        n_buckets = n_bins, \n",
    "                        subplot_titles = [\"\"] + subplot_titles, #mod to get interesting runs\n",
    "                        max_x_location=fop.max_location[0],\n",
    "                        y_ref_value=None)\n",
    "    #plot.write_image(os.path.join(experiment_path, \"Interesting_runs.png\"))#\"F\" + str(function_index+1) + \"_results\"+ str(n_bins) + '.png'))#, width=800, height=1000) \n",
    "    plot.write_image(os.path.join(experiment_path, \"F\" + str(function_index+1) + \"_results\"+ str(n_bins) + '.png'), width=800, height=1000) \n",
    "    plot.show()\n",
    "    #0,5,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing game 0 of 5, agents: ['Vanilla_MCTS', 'Random']\n",
      "Playing game 1 of 5, agents: ['Vanilla_MCTS', 'Random']\n",
      "Playing game 2 of 5, agents: ['Vanilla_MCTS', 'Random']\n",
      "Playing game 3 of 5, agents: ['Vanilla_MCTS', 'Random']\n",
      "Playing game 4 of 5, agents: ['Vanilla_MCTS', 'Random']\n",
      "Playing game 0 of 5, agents: ['Random', 'Vanilla_MCTS']\n",
      "Playing game 1 of 5, agents: ['Random', 'Vanilla_MCTS']\n",
      "Playing game 2 of 5, agents: ['Random', 'Vanilla_MCTS']\n",
      "Playing game 3 of 5, agents: ['Random', 'Vanilla_MCTS']\n",
      "Playing game 4 of 5, agents: ['Random', 'Vanilla_MCTS']\n"
     ]
    }
   ],
   "source": [
    "max_fm = np.inf\n",
    "max_iterations = 200\n",
    "rollouts = 1\n",
    "games = 5\n",
    "#game = chess_64.GameState()\n",
    "game = mnk.GameState(m=3,n=3,k=3)\n",
    "game.set_initial_state()\n",
    "agent0 = mcts.MCTS_Player(max_fm=max_fm, max_iterations = max_iterations, rollouts = rollouts, logs=True)\n",
    "agent1 = siea_mcts.SIEA_MCTS_Player(max_fm=max_fm, max_iterations = max_iterations, rollouts = rollouts, logs=True, es_semantics_l = 0.1, es_semantics_u = 0.5)\n",
    "agent2 = siea_mcts.SIEA_MCTS_Player(max_fm=max_fm, max_iterations = max_iterations, rollouts = rollouts, logs=True, unpaired_evolution=True, name=\"SIEA_MCTS_unpaired\")\n",
    "agent3 = arand.RandomPlayer()\n",
    "eu.play_match([agent0, agent3], game, games, file_path=os.path.join(\"Outputs\",\"Test_match_mnk\"), logs=True, logs_dispatch_after=2)\n",
    "#gp1 = eu.GamePlayer(game.duplicate(), [agent0, agent3])\n",
    "#gp1.play_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess #caps are white\n",
    "import random as rd\n",
    "import Games.chess_64 as chess_64\n",
    "agent0 = mcts.MCTS_Player(max_iterations = 5, rollouts = 1, logs=True)\n",
    "#state1 = chess_64.GameState()\n",
    "state1 = mnk.GameState(m=3,n=3,k=3)\n",
    "state1.set_initial_state()\n",
    "outcomes = {}\n",
    "for i in range(1):\n",
    "    state=state1.duplicate()\n",
    "    while state.is_terminal == False:\n",
    "        #state.make_action(rd.choice(state.available_actions))\n",
    "        state.make_action(agent0.choose_action(state))\n",
    "        #print(state.board)\n",
    "        state.view_game_state()\n",
    "    if state.winner not in outcomes.keys():\n",
    "        outcomes[state.winner] = 1\n",
    "    else:\n",
    "        outcomes[state.winner] += 1\n",
    "print(outcomes)\n",
    "#state.board\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LudoArrow():\n",
    "    def __init__(self,  end_index=None, player_house=None):\n",
    "        self.player_house = player_house #The player whose house this is\n",
    "        self.end_index = end_index\n",
    "\n",
    "class LudoSquare():\n",
    "    def __init__(self, index, is_safe=False, arrow=None, content=None, next_square_index=None, player_house=None, is_victory_path=False):\n",
    "        self.index = index\n",
    "        self.is_safe = is_safe\n",
    "        self.content = content #A list of pieces\n",
    "        self.next_square_index = next_square_index #The index of the next square\n",
    "        self.player_house = player_house #The player whose house this sends to\n",
    "        self.is_victory_path = is_victory_path #Whether this is a victory path square\n",
    "\n",
    "class LudoPiece():\n",
    "    def __init__(self, index, player):\n",
    "        self.index = index\n",
    "        self.player = player\n",
    "        \n",
    "class GameState():\n",
    "    def __init__(self, n_players, pieces_per_player=4):\n",
    "        self.players = [\"red\", \"green\", \"blue\", \"yellow\"]\n",
    "        self.n_players = n_players\n",
    "        self.pieces_per_player = pieces_per_player\n",
    "    def set_initial_state(self):\n",
    "        self.board = {}\n",
    "        self.players_houses = {12:\"red\", 25:\"green\", 38:\"blue\", 51:\"yellow\"}\n",
    "        self.players_starting_index = {\"red\":15, \"green\":28, \"blue\":41, \"yellow\":2}\n",
    "        for i in range(52):\n",
    "            if i in [2, 10, 15, 23, 28, 36, 41, 49]: #safe squares\n",
    "                square = LudoSquare(i, is_safe=True)\n",
    "            elif i in [6, 19, 32, 45]: #squares with immediate arrows\n",
    "                arrow = LudoArrow(end_index=i+1)\n",
    "                square = LudoSquare(i, arrow=arrow)\n",
    "            elif i in [10, 23, 36, 49]: #squares with arrows to the player houses\n",
    "                arrow = LudoArrow(end_index=53, player_house=i)\n",
    "                square = LudoSquare(i, arrow=arrow)\n",
    "            elif i in [13, 26, 39, 52]:\n",
    "                square = LudoSquare(i, player_house=self.players_houses[i])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ecbf9c18c0d04a2116424ae9aa6ca1f2cdd5cba2daaa9a1f143185bb59456a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
